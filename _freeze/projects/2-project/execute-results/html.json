{
  "hash": "0ce506559acda54c2abdef336aa8afe0",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Birth Weight Prediction\nsubtitle: This project predicts birth weight of babies using different factors and shows that a logistic regreesion models performs best. \ntoc: false\n---\n\n\n\n\n\n# Q1\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbirths <- read.csv(\"~/Downloads/birthsnewone.csv\")\nset.seed(123456789)\ni = 1:dim(births)[1]\ni.train <- sample(i,5000,replace=FALSE)\nB.train = births[i.train, ]\nB.test = births[-i.train, ]\nhead(births)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  X Institution.type Plurality.of.birth Gender Race.of.child  Race\n1 1                1                  1      2             1 White\n2 2                1                  1      2             1 White\n3 3                1                  1      2             1 White\n4 4                1                  1      2             2 Black\n5 5                1                  1      1             2 Black\n6 6                1                  1      2             1 White\n  Age.of.father Age.of.mother Education.of.father..years.\n1            50            24                          12\n2            19            18                           9\n3            37            35                          17\n4            39            31                          11\n5            20            19                          11\n6            30            27                          16\n  Education.of.mother..years. Total.Preg BDead Terms Date.LBirth Month.LBirth\n1                          15          2     0     0       32004            3\n2                           9          1     0     0           0            0\n3                          17          2     0     0      112003           11\n4                          16          1     0     0           0            0\n5                          12          1     0     0           0            0\n6                          16          1     0     0           0            0\n  Year.LBirth LOutcome Weeks Prenatal Trimester.Prenatal Visits\n1        2004        1    38        3                  1     10\n2           0        9    35        3                  1      9\n3        2003        1    38        1                  1     20\n4           0        9    38        6                  2     12\n5           0        9    36        4                  2     10\n6           0        9    40        1                  1     20\n  Birth.weight.group Marital Birth.Attendant Numchild Month.Term Year.Term\n1                  5       2               1        1          0         0\n2                  6       2               1        0          0         0\n3                  5       1               1        1          0         0\n4                  5       2               1        0          0         0\n5                  6       2               1        0          0         0\n6                  6       1               1        0          0         0\n  Low.Birth RaceMom RaceDad Mother.Minority Father.Minority HispMom HispDad\n1      Norm       1       2           White        Nonwhite       N       N\n2      Norm       1       1           White           White       N       N\n3      Norm       1       1           White           White       N       N\n4      Norm       2       2        Nonwhite        Nonwhite       N       N\n5      Norm       2       1        Nonwhite           White       N       M\n6      Norm       1       1           White           White       N       N\n  AveCigs Smoker AveDrink Wt.Gain Birth.Weight..g.\n1       0     No        0      50         2865.875\n2      23   Cigs        0      35         3121.250\n3       0     No        0      24         2667.250\n4       0     No        0      30         2979.375\n5       0     No        0      10         3036.125\n6       0     No        0      37         3092.875\n```\n\n\n:::\n:::\n\n\n\n# a.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel <- lm(Birth.Weight..g. ~ ., data = B.train)\n\ntrain_pred <- predict(model, data = B.train)\ntrain_mse <- mean((births$Birth.Weight..g. - train_pred)^2)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in births$Birth.Weight..g. - train_pred: longer object length is not a\nmultiple of shorter object length\n```\n\n\n:::\n\n```{.r .cell-code}\ntest_pred <- predict(model, B.test)\ntest_mse <- mean((births$Birth.Weight..g - test_pred)^2)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in births$Birth.Weight..g - test_pred: longer object length is not a\nmultiple of shorter object length\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Training MSE:\", train_mse, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTraining MSE: 721481.8 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Testing MSE:\", test_mse)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTesting MSE: 710234.1\n```\n\n\n:::\n\n```{.r .cell-code}\n# The training MSE is higher than the testing MSE, which rarely occurs because the model is fit to the training data. The significant predictors are Plurality.of.birth, Gender, RaceWhite, Date.LBirth, Month.LBirth, Weeks, Birth.weight.group, Month.Term, Low.BirthNorm, SmokerNo, and Wt.Gain.\n```\n:::\n\n\n\n# b. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# stepwise <- step(model, direction = \"backward\")\n#summary <- summary(stepwise)\n\n# \"Good predictors\": Plurality.of.birth, Gender, Race, Weeks, Birth.weight.group, Father.Minority, Smoker, Wt.Gain\n\nstep_model <- lm(Birth.Weight..g. ~ Plurality.of.birth + Gender + Race + Weeks + Birth.weight.group + Father.Minority + Smoker + Wt.Gain , data = B.train)\n\nstep_train_pred <- predict(step_model, B.train)\nstep_train_mse <- mean((births$Birth.Weight..g. - step_train_pred)^2)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in births$Birth.Weight..g. - step_train_pred: longer object length is\nnot a multiple of shorter object length\n```\n\n\n:::\n\n```{.r .cell-code}\nstep_test_pred <- predict(step_model, B.test)\nstep_test_mse <- mean((births$Birth.Weight..g. - step_test_pred)^2)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in births$Birth.Weight..g. - step_test_pred: longer object length is\nnot a multiple of shorter object length\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Training MSE:\", step_train_mse, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTraining MSE: 721443.2 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Testing MSE:\", step_test_mse)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTesting MSE: 709755.3\n```\n\n\n:::\n:::\n\n\n\n# c. \nRidge regression with the complete data (births)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Prepare the data\nbirthsLog <- transform(births, lWeight = log(as.numeric(births$Birth.Weight..g.)))\nbirthsLog <- subset(birthsLog, select = -c(Birth.Weight..g., X))\nB.testLog <- transform(B.test, lWeight = log(as.numeric(B.test$Birth.Weight..g.)))\nB.testLog <- subset(B.testLog, select = -c(Birth.Weight..g., X))\n\nbirths2 <- na.omit(birthsLog)\nB.test2 <- na.omit(B.testLog)\n\nx_full <- model.matrix(lWeight ~ ., data = births2)\ny_full <- births2$lWeight\n\nx_test <- model.matrix(lWeight ~ ., data = B.test2)\ny_test <- B.test2$lWeight\n\n# Fit Ridge Regression\nset.seed(705780612)\nlambda.v <- 10^seq(10, -2, length = 100)\nridge_model <- glmnet(x_full, y_full, alpha = 0, lambda = lambda.v)\n\n# Cross-validation to find best lambda\nset.seed(12)\ncv.output <- cv.glmnet(x_full, y_full, alpha = 0)\nqplot <- qplot(log(cv.output$lambda),cv.output$cvsd)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: `qplot()` was deprecated in ggplot2 3.4.0.\n```\n\n\n:::\n\n```{.r .cell-code}\nbestlamb.cv <- cv.output$lambda.min\n\n# Fit the model with the best lambda\nbest_ridge <- glmnet(x_full, y_full, alpha = 0, lambda = bestlamb.cv)\n\n# Predictions\npred.births2 <- predict(best_ridge, newx = x_full, s = bestlamb.cv, type = \"response\")\npred.Btest2 <- predict(best_ridge, newx = x_test, s = bestlamb.cv, type = \"response\")\n\n# Calculate MSE\nMSE.births2 <- mean((y_full - pred.births2)^2) # Training MSE\nMSE.Btest2 <- mean((y_test - pred.Btest2)^2)  # Testing MSE\n\n\ncat(\"Best lambda: \", bestlamb.cv, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nBest lambda:  0.0224084 \n```\n\n\n:::\n\n```{.r .cell-code}\nprint(coef(best_ridge))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n50 x 1 sparse Matrix of class \"dgCMatrix\"\n                                       s0\n(Intercept)                  6.478370e+00\n(Intercept)                  .           \nInstitution.type            -3.084747e-03\nPlurality.of.birth          -3.429659e-02\nGender                      -4.804617e-03\nRace.of.child                3.808047e-04\nRaceOther                    7.947638e-03\nRaceWhite                    6.455639e-03\nAge.of.father               -7.679371e-05\nAge.of.mother                1.002633e-04\nEducation.of.father..years.  3.808010e-04\nEducation.of.mother..years.  4.342688e-04\nTotal.Preg                   9.235997e-04\nBDead                       -2.406430e-02\nTerms                       -1.366699e-03\nDate.LBirth                 -4.986784e-10\nMonth.LBirth                -2.328507e-05\nYear.LBirth                  3.108965e-06\nLOutcome                    -1.891907e-04\nWeeks                        1.828815e-02\nPrenatal                     3.456070e-03\nTrimester.Prenatal          -1.601978e-03\nVisits                       1.621431e-03\nBirth.weight.group           1.238124e-01\nMarital                     -2.870645e-03\nBirth.Attendant              5.054304e-04\nNumchild                     2.665622e-03\nMonth.Term                  -7.218584e-04\nYear.Term                    8.215467e-07\nLow.BirthNorm                1.317013e-01\nRaceMom                     -6.849657e-05\nRaceDad                     -1.444243e-03\nMother.MinorityWhite         7.984752e-03\nFather.MinorityWhite        -4.427625e-03\nHispMomM                     1.217261e-03\nHispMomN                    -1.696298e-03\nHispMomO                    -1.099847e-02\nHispMomP                    -1.272498e-03\nHispMomS                     9.112568e-05\nHispMomU                     2.279497e-02\nHispDadM                    -1.532665e-03\nHispDadN                    -3.089432e-04\nHispDadO                     8.649688e-03\nHispDadP                     1.692276e-03\nHispDadS                     7.593321e-03\nHispDadU                    -1.408813e-02\nAveCigs                     -4.029724e-04\nSmokerNo                     4.647282e-03\nAveDrink                     2.408536e-04\nWt.Gain                      4.650144e-04\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Training MSE: \", MSE.births2, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTraining MSE:  0.006721434 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Testing MSE: \", MSE.Btest2, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTesting MSE:  0.006942309 \n```\n\n\n:::\n\n```{.r .cell-code}\n# The significant predictors are variables like Low.BirthNorm, Birth.weight.group, and Weeks, as they have large coefficients and strong associations to the response. For example, the Weeks coefficient is large (1.828815e-02) compared to others, indicating a strong effect on the response variable. An interesting observation is that AveCigs shows a negative relationship with the response, and SmokerNo has a positive association. The training MSE is 0.0067214 and the testing MSE is 0.0069423, which indicates good model performance and overfitting because the testing MSE is very close to the training MSE.\n```\n:::\n\n\n\n# d. \nUse Lasso Regression Approach to predict the weight of the baby in grams using the\ncomplete data (births) and interpret your results\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbirthsLog <- transform(births, lWeight = log(as.numeric(births$Birth.Weight..g.)))\nbirthsLog <- subset(birthsLog, select = -c(Birth.Weight..g., X))  \nbirths2 <- na.omit(birthsLog)  \n\nx_full <- model.matrix(lWeight ~ ., data = births2) \ny_full <- births2$lWeight\n\nx_test <- model.matrix(lWeight ~ ., data = B.test2)\ny_test <- B.test2$lWeight\n\nlambda.v <- 10^seq(10, -2, length = 100)\n\nset.seed(123)\nmodel.lasso <- glmnet(x_full, y_full, alpha = 1, lambda = lambda.v)\n\ncoeffsL <- coef(model.lasso)\n\nset.seed(12)\ncv.outputL <- cv.glmnet(x_full, y_full, alpha = 1)\nbestlamb.cvL <- cv.outputL$lambda.min\ncat(\"Best Lambda (Lasso):\", bestlamb.cvL, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nBest Lambda (Lasso): 0.0006381994 \n```\n\n\n:::\n\n```{.r .cell-code}\nbest_lasso <- glmnet(x_full, y_full, alpha = 1, lambda = bestlamb.cvL)\n\n# Calculate Training MSE\npred.lasso.train <- predict(best_lasso, newx = x_full, s = bestlamb.cvL, type = \"response\")\npred.lasso.test <- predict(best_lasso, newx = x_test, s = bestlamb.cvL, type = \"response\")\ntrain_mse_lasso <- mean((y_full - pred.lasso.train)^2)\ntest_mse_lasso <- mean((y_test - pred.lasso.test)^2)\n\ncat(\"Training MSE (Lasso):\", train_mse_lasso, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTraining MSE (Lasso): 0.00642802 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Testing MSE (Lasso):\", test_mse_lasso, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTesting MSE (Lasso): 0.006628631 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Plot cross-validation results\nqplot(log(cv.outputL$lambda), cv.outputL$cvm) +\n  geom_errorbar(aes(ymin = cv.outputL$cvm - cv.outputL$cvsd, \n                    ymax = cv.outputL$cvm + cv.outputL$cvsd)) +\n  ggtitle(\"Cross-Validation Error vs Lambda (Log Scale)\") +\n  xlab(\"Log(Lambda)\") +\n  ylab(\"Cross-Validation Error\")\n```\n\n::: {.cell-output-display}\n![](2-project_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#The Lasso regression model has a lower MSE than the linear model (by about 0.003), which shows that the shrinkage technique in Lasso regression can improve model generalization while preventing overfitting. \n\n# Also, the Cross-Validation Error vs Lambda plot shows the error increasing rapidly as the log of lambda moves from -4 to 0.\n```\n:::\n\n\n\n\n# e. \n\n\n::: {.cell}\n\n```{.r .cell-code}\ny.pred.train_lasso <- predict(best_lasso, x_full, s = bestlamb.cvL)\nmse_train_lasso <- mean((y_full - y.pred.train_lasso)^2)\ncat(\"Training MSE (Lasso): \", mse_train_lasso, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTraining MSE (Lasso):  0.00642802 \n```\n\n\n:::\n\n```{.r .cell-code}\ny.pred.test_lasso <- predict(best_lasso, x_test, s = bestlamb.cvL)\nmse_test_lasso <- mean((y_test - y.pred.test_lasso)^2)\ncat(\"Testing MSE (Lasso): \", mse_test_lasso, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTesting MSE (Lasso):  0.006628631 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Create design matrix (x) and response variable (y)\nx <- model.matrix(lWeight ~ ., data = births2)  # Design matrix (excluding intercept)\ny <- births2$lWeight  # Response variable\n```\n:::\n\n\n\nThe multiple linear regression model uses all predictors, resulting in high bias and less flexibility, with training and testing MSE values of 721256.4 and 707930.6, respectively. \n\nThe stepwise regression model, selecting 8 predictors, has only a slightly better MSE (721443.2 and 709755.3) respectively.\n\nRidge regression, with a lambda of 0.00224, after a log transformation, achieves a training MSE of 0.006721434 and a testing MSE of 0.006942309 by applying penalties to predictors, balancing bias and flexibility. These MSE are better that what was shown in stepwise. \n\nThe Lasso model, with similar performance (training MSE: 0.00642802, Testing MSE: 0.006628631), further reduces predictors, offering higher flexibility and lower variance. \n\nBased on the MSE values, Lasso Regression appears to be the best model. It has the lowest MSE on both the training (0.00642802) and testing sets (0.006628631), suggesting a good balance between bias and variance.\n\n# 2\nWrite a short paragraph comparing these approaches in terms of their final number of\npredictors, their bias and their flexibility.\n\nRidge and Lasso regression handle regularization differently. Ridge reduces the size of all coefficients but keeps them in the model, which is great for handling multicollinearity and balancing bias and variance. Lasso can shrink some coefficients to zero, which removes less important predictors and making the model simpler. Ridge is better when you have many small, correlated effects, while Lasso works well when you want to focus on just the key predictors.\n\n\n# a. \nFit a PCR model on the training set, with M principal components chosen by cross\nvalidation. Report the MSE obtained using both data sets (training and testing). along\nwith the value of M principal components selected by cross-validation. Report the\namount of variation explained in the X matrix by those M principal component.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npcrmodel <- pcr(B.train$Birth.Weight..g.~., data=B.train, scale=TRUE, validation=\"CV\")\nsummary(pcrmodel)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nData: \tX dimension: 5000 49 \n\tY dimension: 5000 1\nFit method: svdpc\nNumber of components considered: 49\n\nVALIDATION: RMSEP\nCross-validated using 10 random segments.\n       (Intercept)  1 comps  2 comps  3 comps  4 comps  5 comps  6 comps\nCV           611.4    610.1    608.2    603.8    503.2    336.4    306.3\nadjCV        611.4    610.1    608.2    603.8    502.7    335.0    306.0\n       7 comps  8 comps  9 comps  10 comps  11 comps  12 comps  13 comps\nCV       306.1    306.2    305.9     305.0     304.7     304.5     304.2\nadjCV    305.9    305.9    305.8     304.8     304.6     304.4     304.1\n       14 comps  15 comps  16 comps  17 comps  18 comps  19 comps  20 comps\nCV          299     293.5     293.2     292.3     291.8     291.8     291.6\nadjCV       299     293.2     292.9     292.1     291.6     291.6     291.5\n       21 comps  22 comps  23 comps  24 comps  25 comps  26 comps  27 comps\nCV        290.7     290.0     289.7     289.3     288.7     285.9     285.1\nadjCV     290.5     289.7     289.6     289.3     287.9     285.3     285.1\n       28 comps  29 comps  30 comps  31 comps  32 comps  33 comps  34 comps\nCV        282.7     278.4     278.1     277.5     277.4     256.1     139.9\nadjCV     282.9     278.1     278.0     277.3     277.4     276.9     139.4\n       35 comps  36 comps  37 comps  38 comps  39 comps  40 comps  41 comps\nCV        139.2     139.2     139.1     138.6     138.1     138.1     138.2\nadjCV     139.0     139.1     139.0     138.6     138.0     138.0     138.1\n       42 comps  43 comps  44 comps  45 comps  46 comps  47 comps  48 comps\nCV        138.2     138.2     138.2     138.3     138.3     138.3     138.3\nadjCV     138.2     138.1     138.2     138.2     138.2     138.2     138.2\n       49 comps\nCV        138.5\nadjCV     138.2\n\nTRAINING: % variance explained\n                          1 comps  2 comps  3 comps  4 comps  5 comps  6 comps\nX                         11.8474   22.343   31.207    36.50    41.21    45.71\nB.train$Birth.Weight..g.   0.4779    1.156    2.635    32.49    70.13    74.99\n                          7 comps  8 comps  9 comps  10 comps  11 comps\nX                            49.2    52.60    55.89     59.14     62.07\nB.train$Birth.Weight..g.     75.0    75.07    75.07     75.31     75.36\n                          12 comps  13 comps  14 comps  15 comps  16 comps\nX                            64.78     67.27     69.53     71.71     73.80\nB.train$Birth.Weight..g.     75.42     75.48     76.38     77.23     77.29\n                          17 comps  18 comps  19 comps  20 comps  21 comps\nX                            75.83     77.84     79.82     81.63     83.23\nB.train$Birth.Weight..g.     77.45     77.55     77.55     77.60     77.73\n                          22 comps  23 comps  24 comps  25 comps  26 comps\nX                            84.78     86.27     87.53     88.73     89.92\nB.train$Birth.Weight..g.     77.93     77.94     78.00     78.27     78.65\n                          27 comps  28 comps  29 comps  30 comps  31 comps\nX                            91.07     92.09     93.06     93.96     94.78\nB.train$Birth.Weight..g.     78.66     79.07     79.72     79.74     79.87\n                          32 comps  33 comps  34 comps  35 comps  36 comps\nX                            95.56     96.23     96.85     97.39     97.85\nB.train$Birth.Weight..g.     79.88     79.92     94.87     94.90     94.91\n                          37 comps  38 comps  39 comps  40 comps  41 comps\nX                            98.29     98.71     99.05     99.37     99.69\nB.train$Birth.Weight..g.     94.91     94.95     94.99     94.99     94.99\n                          42 comps  43 comps  44 comps  45 comps  46 comps\nX                            99.85     99.99     99.99       100       100\nB.train$Birth.Weight..g.     94.99     95.00     95.00        95        95\n                          47 comps  48 comps  49 comps\nX                              100       100       100\nB.train$Birth.Weight..g.        95        95        95\n```\n\n\n:::\n\n```{.r .cell-code}\nvalidationplot(pcrmodel)\n```\n\n::: {.cell-output-display}\n![](2-project_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# choose 40 principle components based on analysis of summary of pcr model\n# amount of variation explained by 40 principal components: 99.37% (also from pcr model analysis)\n\n# Check to see the optimal M and the amount of variation\noptimal_M <- which.min(pcrmodel$validation$PRESS)\n\n# Test model\ntrain_predictions <- predict(pcrmodel, newdata = B.train, ncomp = optimal_M)\nMSE.Btrain <- mean((B.train$Birth.Weight..g. - train_predictions)^2)\n\ntest_predictions <- predict(pcrmodel,newdata = B.test , ncomp = optimal_M)\nMSE.Btest <- mean((B.test$Birth.Weight..g. - test_predictions)^2)\n\ncat(\"Optimal M:\", optimal_M, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOptimal M: 40 \n```\n\n\n:::\n\n```{.r .cell-code}\n#cat(\"Amount of Variance explained by the optimal M:\", explained_variance, \"\\n\")\ncat(\"Training MSE:\", MSE.Btrain, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTraining MSE: 18709.24 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Testing MSE:\", MSE.Btest, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTesting MSE: 19207.04 \n```\n\n\n:::\n\n```{.r .cell-code}\n# The validation plot is a visualization for the optimal M by showing that the RMSEP is lowest beginning at around 38.\n```\n:::\n\n\n\n# b. \nFit a PLS model on the training set, with M principal components chosen by cross\nvalidation. Report the MSE obtained using both data sets (training and testing), along\nwith the value of M principal components selected by cross-validation. Report the\namount of variation explained in the X matrix by those M principal component.\nNote: Use 85% as your threshold for the amount of variation in the X matrix\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplsmodel <- plsr(B.train$Birth.Weight..g.~., data=B.train, scale=TRUE, validation=\"CV\")\nsummary(plsmodel)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nData: \tX dimension: 5000 49 \n\tY dimension: 5000 1\nFit method: kernelpls\nNumber of components considered: 49\n\nVALIDATION: RMSEP\nCross-validated using 10 random segments.\n       (Intercept)  1 comps  2 comps  3 comps  4 comps  5 comps  6 comps\nCV           611.4    284.8    248.3    197.6    162.1    146.8    141.5\nadjCV        611.4    284.6    248.2    197.5    161.8    146.6    141.4\n       7 comps  8 comps  9 comps  10 comps  11 comps  12 comps  13 comps\nCV       138.7    138.2    138.1     138.1     138.1     138.1     138.1\nadjCV    138.7    138.1    138.1     138.0     138.0     138.1     138.1\n       14 comps  15 comps  16 comps  17 comps  18 comps  19 comps  20 comps\nCV        138.1     138.1     138.1     138.1     138.1     138.1     138.1\nadjCV     138.1     138.1     138.1     138.1     138.1     138.1     138.1\n       21 comps  22 comps  23 comps  24 comps  25 comps  26 comps  27 comps\nCV        138.1     138.2     138.2     138.2     138.2     138.2     138.2\nadjCV     138.1     138.1     138.1     138.1     138.1     138.1     138.1\n       28 comps  29 comps  30 comps  31 comps  32 comps  33 comps  34 comps\nCV        138.2     138.2     138.2     138.2     138.2     138.2     138.2\nadjCV     138.1     138.1     138.1     138.1     138.1     138.1     138.1\n       35 comps  36 comps  37 comps  38 comps  39 comps  40 comps  41 comps\nCV        138.2     138.2     138.2     138.2     138.2     138.2     138.2\nadjCV     138.1     138.1     138.1     138.1     138.1     138.1     138.1\n       42 comps  43 comps  44 comps  45 comps  46 comps  47 comps  48 comps\nCV        138.2     138.2     138.2     138.2     138.2     138.2     138.2\nadjCV     138.1     138.1     138.1     138.1     138.1     138.1     138.1\n       49 comps\nCV        138.2\nadjCV     138.1\n\nTRAINING: % variance explained\n                          1 comps  2 comps  3 comps  4 comps  5 comps  6 comps\nX                           5.585    15.15    20.14    26.76    32.35    39.33\nB.train$Birth.Weight..g.   78.466    83.66    89.78    93.17    94.37    94.76\n                          7 comps  8 comps  9 comps  10 comps  11 comps\nX                           43.83    45.97    48.90     52.03     53.96\nB.train$Birth.Weight..g.    94.95    94.99    94.99     94.99     95.00\n                          12 comps  13 comps  14 comps  15 comps  16 comps\nX                            55.52      57.5     59.42     61.21     62.78\nB.train$Birth.Weight..g.     95.00      95.0     95.00     95.00     95.00\n                          17 comps  18 comps  19 comps  20 comps  21 comps\nX                            64.59     66.67     68.34     70.63     72.17\nB.train$Birth.Weight..g.     95.00     95.00     95.00     95.00     95.00\n                          22 comps  23 comps  24 comps  25 comps  26 comps\nX                            73.83     75.04     76.28     77.71     79.09\nB.train$Birth.Weight..g.     95.00     95.00     95.00     95.00     95.00\n                          27 comps  28 comps  29 comps  30 comps  31 comps\nX                            81.23     82.88     83.89     85.07     86.27\nB.train$Birth.Weight..g.     95.00     95.00     95.00     95.00     95.00\n                          32 comps  33 comps  34 comps  35 comps  36 comps\nX                            87.65     88.55     89.26     90.46     91.37\nB.train$Birth.Weight..g.     95.00     95.00     95.00     95.00     95.00\n                          37 comps  38 comps  39 comps  40 comps  41 comps\nX                            92.52     93.49     94.46     95.91      97.2\nB.train$Birth.Weight..g.     95.00     95.00     95.00     95.00      95.0\n                          42 comps  43 comps  44 comps  45 comps  46 comps\nX                            97.95     98.45     99.39       100     100.1\nB.train$Birth.Weight..g.     95.00     95.00     95.00        95      95.0\n                          47 comps  48 comps  49 comps\nX                            100.2     100.3     100.5\nB.train$Birth.Weight..g.      95.0      95.0      95.0\n```\n\n\n:::\n\n```{.r .cell-code}\nvalidationplot(plsmodel)\n```\n\n::: {.cell-output-display}\n![](2-project_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# choose 10 principal components (from summary analysis)\n# amount of variation explained by 10 principal components: 94.99%\n\n# Check to see the optimal M and the amount of variation\noptimal_M <- which.min(plsmodel$validation$PRESS)\nexplained_variance <- cumsum(explvar(plsmodel))\n\ntrain_predictions <- predict(plsmodel, newdata = B.train, ncomp = optimal_M)\nMSE.Btrain <- mean((B.train$Birth.Weight..g. - train_predictions)^2)\n\ntest_predictions <- predict(plsmodel,newdata = B.test , ncomp = optimal_M)\nMSE.Btest <- mean((B.test$Birth.Weight..g. - test_predictions)^2)\n\ncat(\"Optimal M:\", optimal_M, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOptimal M: 10 \n```\n\n\n:::\n\n```{.r .cell-code}\n#cat(\"Amount of Variance explained by the optimal M:\", explained_variance, \"\\n\")\ncat(\"Training MSE:\", MSE.Btrain, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTraining MSE: 18701.52 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Testing MSE:\", MSE.Btest, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTesting MSE: 19238.18 \n```\n\n\n:::\n\n```{.r .cell-code}\n# The validation plot is a visualization for the optimal M by showing that the RMSEP is lowest beginning at a little before 10.\n```\n:::\n\n\n\n# c.\nFit a GAM on the training data, using “the weight of the baby in grams” as the response\nand the features selected in the previous step BIC function (Question 1 Part b) as your\npredictors. Plot the results, and explain your findings.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngammodel <- gam(B.train$Birth.Weight..g. ~ \n                  s(Weeks) + \n                  s(Wt.Gain) + \n                  Plurality.of.birth + Gender + Race + \n                  Birth.weight.group + Father.Minority + Smoker, \n                data = B.train)\n\n#summary(gammodel)\n\npar(mfrow = c(2, 2)) \n#plot(gammodel, se = TRUE, shade = TRUE)\n\ntrain_predictions <- predict(gammodel, newdata = B.train)\ntrain_mse <- mean((B.train$Birth.Weight..g. - train_predictions)^2)\ncat(\"Training MSE:\", train_mse, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTraining MSE: 18783.65 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Unfortunately, I've run into errors with the plot function.\n\nB.train$Predicted <- predict(gammodel, newdata = B.train)\n\nggplot(B.train, aes(x = Birth.Weight..g., y = Predicted)) +\n  geom_point(alpha = 0.5) +\n  geom_abline(slope = 1, intercept = 0, color = \"red\") +\n  theme_minimal() +\n  labs(\n    title = \"Actual vs Predicted Birth Weight\",\n    x = \"Actual Birth Weight (grams)\",\n    y = \"Predicted Birth Weight (grams)\"\n)\n```\n\n::: {.cell-output-display}\n![](2-project_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\nThe actual vs. predicted weights plot shows that the GAM model fits the training data very well. It accurately predicts the baby weights given the significant predictors chosen from the step BIC function. Also, the training and testing MSE are relatively close and does not overfit. The testing MSE is higher than the training, as expected. \n\n# d. \nEvaluate the model obtained on the testing data set, and explain the results obtained.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(splines)\n\ngammodel2 <- gam(Birth.Weight..g. ~ Plurality.of.birth + Gender + Race + s(Weeks, k = 5) + Birth.weight.group + Father.Minority + Smoker + s(Wt.Gain, k = 5),data = B.test)\n#summary(gammodel2)\n\nB.test$Predicted <- predict(gammodel2, newdata = B.test)\ntest_mse <- mean((B.test$Birth.Weight..g. - B.test$Predicted)^2)\n\nss_total <- sum((B.test$Birth.Weight..g. - mean(B.test$Birth.Weight..g.))^2)\nss_residual <- sum((B.test$Birth.Weight..g. - B.test$Predicted)^2)\nr_squared <- 1 - (ss_residual / ss_total)\n\nggplot(B.test, aes(x = Birth.Weight..g., y = Predicted)) +\n  geom_point(alpha = 0.5, color = \"blue\") +\n  geom_abline(slope = 1, intercept = 0, color = \"red\") +\n  theme_minimal() +\nlabs(\n  title = \"Actual vs Predicted Birth Weight (Testing Data)\",\n  x = \"Actual Birth Weight (grams)\",\n  y = \"Predicted Birth Weight (grams)\"\n)\n```\n\n::: {.cell-output-display}\n![](2-project_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n\n```{.r .cell-code}\ncat(\"Testing MSE:\", test_mse, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTesting MSE: 19084.45 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Testing R-squared:\", r_squared, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTesting R-squared: 0.9476297 \n```\n\n\n:::\n:::\n\n\nThe GAM model fits the data very well with a high r squared, and the the model does not overfit as the testing MSE is similar to the training MSE and does not overfit. The testing MSE is higher than the training, as expected. \n\n# e.\nFor which of the predictor variables in part c, if any, an evidence of a non-linear\nrelationship with the response variable?\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(gammodel)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nFamily: gaussian \nLink function: identity \n\nFormula:\nB.train$Birth.Weight..g. ~ s(Weeks) + s(Wt.Gain) + Plurality.of.birth + \n    Gender + Race + Birth.weight.group + Father.Minority + Smoker\n\nParametric coefficients:\n                     Estimate Std. Error t value Pr(>|t|)    \n(Intercept)           528.934     20.235  26.139  < 2e-16 ***\nPlurality.of.birth    -37.088     10.774  -3.442 0.000582 ***\nGender                 -9.625      3.921  -2.455 0.014128 *  \nRaceOther              10.493     10.307   1.018 0.308749    \nRaceWhite              22.275      9.578   2.326 0.020073 *  \nBirth.weight.group    455.856      2.042 223.264  < 2e-16 ***\nFather.MinorityWhite    5.287      8.804   0.601 0.548183    \nSmokerNo               27.350      6.716   4.072 4.73e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nApproximate significance of smooth terms:\n             edf Ref.df      F p-value    \ns(Weeks)   2.901  3.669 47.305 < 2e-16 ***\ns(Wt.Gain) 2.039  2.608  4.177 0.00733 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-sq.(adj) =   0.95   Deviance explained =   95%\nGCV =  18881  Scale est. = 18832     n = 5000\n```\n\n\n:::\n:::\n\n\n\n\n\"Weeks\" shows evidence of a moderate non-linear relationship with birth weight.\n\"Wt.Gain\" shows a weak non-linear relationship, suggesting it is closer to linear but not completely. \nThey both have p-values less than 0.05, suggesting that there is evidence for a non-linear relationship between the variables.\n\n\n",
    "supporting": [
      "2-project_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}